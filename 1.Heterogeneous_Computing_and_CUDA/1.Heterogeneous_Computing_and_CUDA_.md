# 1.0 并行计算与计算机架构

![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/CUDA_C.png)

## 并行与并发

### 并发(Concurrent)

并发是一个CPU处理器同时处理多个线程任务。（宏观上是同时处理多个任务，微观上其实是CPU在多个线程之间快速的交替执行。操作系统中有一个组件叫做任务调度器，它将CPU的时间片（windows下时间片最小约为15毫秒）配给各个线程使用，在一个时间段的线程运行时，其他线程处于挂起状态，这种就称之为并发。）

### 并行(parallel)

并行是多个CPU处理器同时处理多个线程任务。（当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这就被称之为并行。）

## 关于串行与并行程序

​        我们最早的计算机肯定不是并行的，但是可以做成多线程的，因为当时一个CPU只有一个核，所以不可能一个核同时执行两个计算，后来我们的应用逐步要求计算量越来越高，所以单核的计算速度也在逐步上升，后来大规模并行应用产生了，我们迫切的需要能够同时处理很多数据的机器，比如图像处理，以及处理大规模的同时访问的服务器后台。

​        写并行程序和串行程序的最大区别就是，写串行程序可能不需要学习不同的硬件平台，但是写并行程序就需要对硬件有一定的了解了。

## 并行性

写并行程序主要是分解任务，我们一般把一个程序看成是指令和数据的组合，当然并行也可以分为这两种：

- 指令并行
- 数据并行

我们的任务更加关注数据并行，所以我们的主要任务是分析数据的相关性，哪些可以并行，哪些不能不行。

## 基本并行编程概念

### ①指令级并行（CPU流水线）

指令级并行是最细粒度、最微观的并行

![image-20240720121702150](C:/Users/13155/AppData/Roaming/Typora/typora-user-images/image-20240720121702150.png)

### ②线程级并行（共享存储式并行）（OpenMP、OpenCL、OpenACC）

细粒度其次。

![image-20240720142721079](C:/Users/13155/AppData/Roaming/Typora/typora-user-images/image-20240720142721079.png)

线程级并行：在一个进程的内部进行任务细分，多个线程同时进行。

· 主线程通过OpenMP、OpenCL、OpenACC或其他多线程实现的规范，可以再该进程空间内在主线程的基础上派生很多的派生线程。这些派生线程可以执行一部分派生的任务，都是在同一个进程空间内完成任务，不需要再向操作系统请求共享数据，内部即可完成数据共享。

### ③分布式并行（‌也称为请求级并行）‌（MPI）

细粒度最低（最粗）。

操作系统将程序分配到内存中是分配了一个进程空间，这个进程空间是受到保护独立于其他程序的。

将数据和指令分别放到不同的进程空间中执行，就是一个分布式并行的模型。

不同进程中的数据和指令都是彼此封闭和独立的。

分布式计算系统的一个计算节点和另外一个计算节点之间内存地址空间不共享，甚至存储芯片在硬件上已经是隔离的了。每一个节点都有自己的操作系统。

通过资源管理系统统一调配和发起同一个计算任务，对跨节点的进程进行管理。

![image-20240720121752515](C:\Users\13155\AppData\Roaming\Typora\typora-user-images\image-20240720121752515.png)



## 进程和线程

进程：一个进行中的程序。包括需要处理的程序和数据，指令加数据就构成了一个进程。

线程：线程是在进程内部的。一个进程空间内可以包含多个线程，每个线程都是在处理进程空间内部的数据。

**进程**（Process）是操作系统分配资源的基本单位，它是一个独立运行的程序及其运行环境的集合，包括代码、数据以及系统为进行该进程而调配的各种资源。在操作系统中，进程是资源分配的基本单位，它拥有一个独立的虚拟地址空间，包含一套独立的系统资源，如文件描述符、信号处理、内存管理等。进程之间通过进程间通信（IPC）机制进行通信。

**线程**（Thread）是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。线程共享进程所拥有的资源，包括内存、文件句柄等，但每个线程有自己独立的栈和寄存器状态。线程之间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以避免数据竞争。

总结来说，进程和线程的主要区别在于：

1. **资源占用**：进程是资源分配的基本单位，拥有独立的内存空间和系统资源；而线程是CPU调度的基本单位，共享进程的资源。
2. **独立性**：进程之间是相互独立的，一个进程无法访问另一个进程的地址空间；而线程是进程的一个实体，多个线程共享同一份进程的资源。
3. **并发性**：进程之间可以并发执行，但进程间的切换开销较大；线程之间也可以并发执行，并且线程间的切换开销较小。
4. **系统开销**：由于进程拥有独立的内存空间和系统资源，因此创建和销毁进程的系统开销较大；而线程共享进程的资源，因此创建和销毁线程的系统开销较小。
5. **通信方式**：进程之间需要通过IPC机制进行通信；而线程之间可以通过读写共享内存来进行通信。



## 关于Linux内核级线程

在Linux中，内核线程通常被称为“内核级线程”或“内核线程”，而不是“内核进程”，这是基于以下几个关键点和特性：

1. **定义与空间运行**：
   - 内核线程：是在内核空间中运行的一种特殊类型的进程。它们由内核创建和管理，独立于用户空间的应用程序进程。
   - 进程：是程序的执行实例，通常包括用户空间进程和内核空间进程（虽然后者更常被称为“内核线程”）。用户空间进程在用户空间中运行，而内核线程则在内核空间中运行。
2. **特点与用途**：
   - 内核线程：
     - 在内核空间运行，具有更高的权限和访问级别。
     - 独立于用户空间，与用户空间的应用程序进程相互独立，不受用户进程的影响。
     - 通常用于执行与内核相关的任务，如调度、中断处理、内存管理等。
   - 进程（尤其是用户空间进程）：主要用于执行用户级任务，与内核级任务相对独立。
3. **管理与调度**：
   - 内核线程由内核直接管理和调度，以确保系统级任务的及时执行。
   - 用户空间进程则由操作系统通过进程调度器进行管理和调度，以实现多任务的并发执行。
4. **系统开销与效率**：
   - 由于内核线程直接在内核空间中运行，它们通常具有较低的系统开销和较高的执行效率。
   - 与之相比，用户空间进程在需要执行内核级任务时（如系统调用），需要进行上下文切换，从而增加了系统开销。

综上所述，Linux选择使用“内核线程”而不是“内核进程”这一术语，主要是为了强调这些特殊进程在内核空间中运行、由内核直接管理和调度、以及用于执行系统级任务的特点。同时，这也有助于区分它们与用户空间进程之间的不同。

在实际应用中，内核线程在Linux系统中扮演着至关重要的角色，它们负责处理各种底层任务和中断，确保系统的稳定运行和高效执行。



## MPI（进程级并行）

Message Passing Interface（MPI）：一种基于信息传递的并行编程技术，定义了一组具有可移植性的编程接口标准（并非一种语言或者接口）。支持点对点通信和广播。MPI 的目标是高性能、大规模性、可移植性，在今天仍为高性能计算的主要模型。OpenMPI 函数库，微软 MPI 文档

## 数据并行程序设计的步骤

1. 块划分，把一整块数据切成小块，每个小块随机的划分给一个线程，每个块的执行顺序随机（关于线程的概念可以去看《深入理解计算机系统》）

| thread |   1   |   2   |   3   |    4     | 5        |
| :----: | :---: | :---: | :---: | :------: | :------- |
| block  | 1 2 3 | 4 5 6 | 7 8 9 | 10 11 12 | 13 14 15 |

1. 周期划分，线程按照顺序处理相邻的数据块，每个线程处理多个数据块，比如我们有五个线程，线程1执行块1，线程2执行块2…..线程5执行块5，线程1执行块6

| thread |  1   |  2   |  3   |  4   | 5    | 1    | 2    | 3    | 4    | 5    | 1    | 2    | 3    | 4    | 5    |
| :----: | :--: | :--: | :--: | :--: | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| block  |  1   |  2   |  3   |  4   | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   |

下面是示意图，注意颜色相同的块使用的同一个线程，从执行顺序上看如下：
![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/2.png)
下面是数据集上的划分上看：
![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/3.png)

**不同的数据划分严重影响程序性能，所以针对不同的问题和不同计算机结构，我们要通过和理论和试验共同来决定最终最优的数据划分。**

## 计算机架构的划分

### 佛林分类法(Flynn’s Taxonomy)

划分不同计算机结构的方法有很多，广泛使用的一种被称为佛林分类法Flynn’s Taxonomy，他根据指令和数据进入CPU的方式分类，分为以下四类：
![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/4.png)

分别以数据和指令进行分析：

- 单指令单数据SISD（传统串行计算机，386）
- 单指令多数据SIMD（并行架构，比如向量机，所有核心指令唯一，但是数据不同，现在CPU基本都有这类的向量指令）
- 多指令单数据MISD（少见，多个指令围殴一个数据）
- 多指令多数据MIMD（并行架构，多核心，多指令，异步处理多个数据流，从而实现空间上的并行，MIMD多数情况下包含SIMD，就是MIMD有很多计算核，计算核支持SIMD）

为了提高并行的计算能力，我们要从架构上实现下面这些性能提升：

- 降低延迟
- 提高带宽
- 提高吞吐量

**延迟**是指操作从开始到结束所需要的时间，一般用微秒计算，延迟越低越好。
**带宽**是单位时间内处理的数据量，一般用MB/s或者GB/s表示。
**吞吐量**是单位时间内成功处理的运算数量，一般用gflops来表示（十亿次浮点计算），吞吐量和延迟有一定关系，都是反应计算速度的，一个(吞吐量)是时间除以运算次数，得到的是单位次数用的时间–延迟，一个(延迟)是运算次数除以时间，得到的是单位时间执行次数–吞吐量。

### 根据内存划分计算机架构

计算机架构也可以根据内存进行划分：

1. **分布式内存的多节点系统**
2. **共享内存的多处理器系统**

第一个(**分布式内存的多节点系统**)更大，通常叫做**集群**，就是一个机房好多机箱，每个机箱都有内存处理器电源等一些列硬件，通过网络互动，这样组成的就是分布式。
![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/5.png)

第二个(**共享内存的多处理器系统**)是单个主板有多个处理器，他们共享相同的主板上的内存，内存寻址空间相同，通过PCIe和内存互动。
![img](https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/6.png)
**多个处理器可以分多片处理器，和单片多核（众核many-core)**，也就是有些主板上挂了好多片处理器，也有的是一个主板上就一个处理器，但是这个处理器里面有几百个核。
**GPU就属于众核系统。**当然**现在CPU也都是多核的了**，但是他们还是有很大区别的：

- **CPU**适合执行**复杂的逻辑**，比如多分支，其核心比较重（复杂）
- **GPU**适合执行**简单的逻辑**，大量的数据计算，其吞吐量更高，但是核心比较轻（结构简单）

# 1.1 异构计算与CUDA

## 异构

异构是按照指令集划分或者按照内存结构划分，但是我觉得只要两片CPU型号不一样就应该叫异构（这个想法先保留，对错不确定）。

x86 CPU+GPU的这种异构应该是最常见的，也有CPU+FPGA，CPU+DSP 等各种各样的组合，CPU+GPU在每个笔记本或者台式机上都能找到。当然超级计算机大部分也采用异构计算的方式来提高吞吐量。
异构架构虽然比传统的同构架构运算量更大，但是其应用复杂度更高，因为要在两个设备上进行计算，控制，传输，这些都需要人为干预，而同构的架构下，硬件部分自己完成控制，不需要人为设计。

## 异构架构举例

举一个我用的工作站的构成，我使用的是一台 intel i7-4790 CPU加上两台Titan x GPU构成的工作站，GPU插在主板的PCIe卡口上，运行程序的时候，CPU像是一个控制者，指挥两台Titan完成工作后进行汇总，和下一步工作安排，所以CPU我们可以把它看做一个指挥者，主机端，host，而完成大量计算的GPU是我们的计算设备，device。
![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/1.png)
上面这张图能大致反应CPU和GPU的架构不同。

- 左图：一个四核CPU一般有四个ALU，ALU是完成逻辑计算的核心，也是我们平时说四核八核的核，控制单元，缓存也在片上，DRAM是内存，一般不在片上，CPU通过总线访问内存。
- 右图：GPU，绿色小方块是ALU，我们注意红色框内的部分SM，这一组ALU公用一个Control单元和Cache，这个部分相当于一个完整的多核CPU，但是不同的是ALU多了，control部分变小，可见计算能力提升了，控制能力减弱了，所以对于控制（逻辑）复杂的程序，一个GPU的SM是没办法和CPU比较的，但是对了逻辑简单，数据量大的任务，GPU更搞笑，并且，注意，一个GPU有好多个SM，而且越来越多。

**CPU和GPU之间通过PCIe总线连接，用于传递指令和数据**，这部分也是后面要讨论的性能瓶颈之一。
一个异构应用包含两种以上架构，所以代码也包括不止一部分：

- 主机代码
- 设备代码

主机代码在主机端运行，被编译成主机架构的机器码，设备端的在设备上执行，被编译成设备架构的机器码，所以主机端的机器码和设备端的机器码是隔离的，自己执行自己的，没办法交换执行。
**主机端代码主要是控制设备，完成数据传输等控制类工作，设备端主要的任务就是计算。**
因为当没有GPU的时候CPU也能完成这些计算，只是速度会慢很多，所以可以把GPU看成CPU的一个加速设备。
NVIDIA目前的计算平台（不是架构）有：

- Tegra
- Geforce
- Quadro
- Tesla

每个平太针对不同的应用场景，比如Tegra用于嵌入式，Geforce是我们平时打游戏用到，Tesla是我们昨天租的那台腾讯云的，主要用于计算。

上面是根据应用场景分类的几种平台。

衡量GPU计算能力的主要靠下面两种***容量\***特征：

- CUDA核心数量（越多越好）
- 内存大小（越大越好）

相应的也有计算能力的***性能\***指标:

- 峰值计算能力
- 内存带宽

nvidia自己有一套描述GPU计算能力的代码，其名字就是“计算能力”，主要区分不同的架构，早其架构的计算能力不一定比新架构的计算能力强

| 计算能力 | 架构名  |
| :------- | :------ |
| 1.x      | Tesla   |
| 2.x      | Fermi   |
| 3.x      | Kepler  |
| 4.x      | Maxwell |
| 5.x      | Pascal  |
| 6.x      | Volta   |

这里的Tesla架构，与上面的Tesla平台不同，不要混淆，一个是平台名字，一个是架构名字

## CPU与GPU的计算特点

CPU和GPU相互配合，各有所长，各有所短，不能说GPU就是比CPU强这种幼稚的话：
![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/2.png)

低并行逻辑复杂的程序适合用CPU
高并行逻辑简单的大数据计算适合GPU

一个程序可以进行如下分解，串行部分和并行部分：
![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/3.png)

## CPU和GPU线程的区别

1. CPU线程是重量级实体，操作系统交替执行线程，线程上下文切换花销很大
2. GPU线程是轻量级的，GPU应用一般包含成千上万的线程，多数在排队状态，线程之间切换基本没有开销。
3. CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU核则是大量线程，最大幅度提高吞吐量

## CUDA：一种异构计算平台

CUDA平台不是单单指软件或者硬件，而是建立在Nvidia GPU上的一整套平台，并扩展出多语言支持
![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/4.png)

CUDA C 是标准ANSI C语言的扩展，扩展出一些语法和关键字来编写设备端代码，而且CUDA库本身提供了大量API来操作设备完成计算。

对于API也有两种不同的层次，一种相对交高层，一种相对底层。

- CUDA驱动API
- CUDA运行时API

![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/5.png)

驱动API是低级的API，使用相对困难，运行时API是高级API使用简单，其实现基于驱动API。
这两种API是互斥的，也就是你只能用一个，两者之间的函数不可以混合调用，只能用其中的一个库。

一个CUDA应用通常可以分解为两部分，

- CPU 主机端代码
- GPU 设备端代码

CUDA nvcc编译器会自动分离你代码里面的不同部分，如图中主机代码用C写成，使用本地的C语言编译器编译，设备端代码，也就是核函数，用CUDA C编写，通过nvcc编译，链接阶段，在内核程序调用或者明显的GPU设备操作时，添加运行时库。

**注意：核函数是我们后面主要接触的一段代码，就是设备上执行的程序段**

![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/6.png)

nvcc 是从LLVM开源编译系统为基础开发的。

![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/7.png)

CUDA工具箱提供编译器，数学库，调试优化等工具，当然CUDA的文档是相当完善的，可以去查阅，当然在我们基本了解基础结构的情况下，直接上来看文档会变得机械化。

![img](https://face2ai.com/CUDA-F-1-1-%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97-CUDA/8.png)

